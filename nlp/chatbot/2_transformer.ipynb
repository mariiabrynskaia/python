{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tLq0kv2VOKPk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('daily_dialog') # датасет по повседневным диалогам на разные темы, позиционируется как more human-like speech"
      ],
      "metadata": {
        "id": "NF1LVZJaRT1v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# реплики диалогов в ячейках записаны как str через запятую --> preprocess все реплики одного диалога как один str\n",
        "def preprocess(df):\n",
        "    df['dialog'] = \" \".join(df['dialog'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "nXF0Y-_ZSd5n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "BpVruzhTeBGs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('microsoft/DialoGPT-small')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "H0c85IV0RUW4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing(df):\n",
        "    tokenized_df = tokenizer(df['dialog'], max_length=128, padding='max_length', truncation=True)\n",
        "    tokenized_df['labels'] = tokenized_df['input_ids'][:]\n",
        "    return tokenized_df"
      ],
      "metadata": {
        "id": "He6F60J_RelI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.map(tokenizing, batched=True)"
      ],
      "metadata": {
        "id": "Z-nvajg5Sm9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data['train']\n",
        "eval_data = data['validation']"
      ],
      "metadata": {
        "id": "xX2UWElrT1Bk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/chatbot_model',\n",
        "    num_train_epochs=5,\n",
        "    learning_rate = 0.00005,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    prediction_loss_only=True,\n",
        "    save_total_limit=2,\n",
        "    save_steps=340,\n",
        "    logging_steps=340,\n",
        "    overwrite_output_dir=True,\n",
        ")"
      ],
      "metadata": {
        "id": "SxnlXqmtRfxq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data\n",
        ")"
      ],
      "metadata": {
        "id": "vZgc347QRjcQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hnju6Y4CUHpk",
        "outputId": "5cdf7104-3165-4f48-f42b-dce274fe1a50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3475' max='3475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3475/3475 17:38, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.343000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>1.866100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>1.838900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>1.755600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>1.714300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>1.697600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>1.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>1.662300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3475, training_loss=1.82918417731635, metrics={'train_runtime': 1060.8864, 'train_samples_per_second': 52.4, 'train_steps_per_second': 3.276, 'total_flos': 3631306014720000.0, 'train_loss': 1.82918417731635, 'epoch': 5.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/chatbot_model\")\n",
        "tokenizer.save_pretrained(\"/content/chatbot_tokenizer\")"
      ],
      "metadata": {
        "id": "B_r2FHEoUd96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = GPT2LMHeadModel.from_pretrained(\"/content/chatbot_model\")\n",
        "my_model.config.pad_token_id = my_model.config.eos_token_id\n",
        "my_tokenizer = GPT2Tokenizer.from_pretrained(\"/content/chatbot_tokenizer\")"
      ],
      "metadata": {
        "id": "kGMy5kO8Uf8P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(user_input):\n",
        "    text = user_input.lower()\n",
        "    input_ids = my_tokenizer.encode(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = my_model.generate(input_ids, attention_mask=attention_mask, max_length=32, num_beams=5, no_repeat_ngram_size=2)\n",
        "        final_output = my_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        final_output = final_output.replace(text, '').strip()\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "lZ3Fx3btUv18"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "print('To end the dialogue, print \"bye\"')\n",
        "while True:\n",
        "    user_input = input('\\033[91m'+'User: '+'\\033[0m')\n",
        "    if user_input.lower() == 'bye':\n",
        "        print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "        print('Goodbye!')\n",
        "        break\n",
        "    bot_response = get_response(user_input)\n",
        "    print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "    print(bot_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQihY-0GU5-N",
        "outputId": "ded7465f-ba32-4596-8ab9-dcdd078cbf83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mChatBot: \u001b[0mTo end the dialogue, print \"bye\"\n",
            "\u001b[91mUser: \u001b[0mhello, how do you do?\n",
            "\u001b[92mChatBot: \u001b[0mHello, I ’ m calling to ask you a few questions about your new job. Can I help you?\n",
            "\u001b[91mUser: \u001b[0mwhere do you work?\n",
            "\u001b[92mChatBot: \u001b[0mI work in a publishing house.\n",
            "\u001b[91mUser: \u001b[0mwhat are your hobbies? \n",
            "\u001b[92mChatBot: \u001b[0mI like to play golf, read a lot of books, and listen to classical music. I also like collecting stamps.\n",
            "\u001b[91mUser: \u001b[0mdo you prefer cats or dogs? \n",
            "\u001b[92mChatBot: \u001b[0mI prefer dogs.\n",
            "\u001b[91mUser: \u001b[0mwhat exercises can i do to gain muscles? \n",
            "\u001b[92mChatBot: \u001b[0mYou can do push-ups, pull-up or sit-down exercises.\n",
            "\u001b[91mUser: \u001b[0mhow do i stay healthy in winter? \n",
            "\u001b[92mChatBot: \u001b[0mDon't worry about it. It's just a part of being a member of the family.\n",
            "\u001b[91mUser: \u001b[0mhow do i make a pizza?\n",
            "\u001b[92mChatBot: \u001b[0mPut the dough in the oven, and wait for it to be ready. Then put it on the grill.\n",
            "\u001b[91mUser: \u001b[0mbye\n",
            "\u001b[92mChatBot: \u001b[0mGoodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задаю некоторые вопросы такие же, что спрашивала и у tf-idf, чтобы посмотреть разницу в ответах."
      ],
      "metadata": {
        "id": "RmaJSe97e-qf"
      }
    }
  ]
}