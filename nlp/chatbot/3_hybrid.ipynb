{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bXfbN99LGgW8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyiimt5WMKep"
      },
      "source": [
        "Натренированный трансформер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WmqYK9AvIb0n"
      },
      "outputs": [],
      "source": [
        "my_model = GPT2LMHeadModel.from_pretrained(\"/content/chatbot_model\")\n",
        "my_model.config.pad_token_id = my_model.config.eos_token_id\n",
        "my_tokenizer = GPT2Tokenizer.from_pretrained(\"/content/chatbot_tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L00VkWWMQMI"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aD5PWA_qHWiC"
      },
      "outputs": [],
      "source": [
        "df = load_dataset('alespalla/chatbot_instruction_prompts')['train'].to_pandas()\n",
        "df['response'] = df['response'].str.lower()\n",
        "df['prompt'] = df['prompt'].str.lower()\n",
        "vector = TfidfVectorizer()\n",
        "tfidf_matrix = vector.fit_transform(df['prompt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEvoeSzPMXM-"
      },
      "source": [
        "Модель для семантического сходства. <br>\n",
        "В отличие от косинусного сходства, которое смотрит на частоту повторения слов,<br>\n",
        "семантическое сходство сравнивает значения слов и контекст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jqCfyxXxH4y3"
      },
      "outputs": [],
      "source": [
        "semantic_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iF32FnopJBgd"
      },
      "outputs": [],
      "source": [
        "# подсчет семантического сходства\n",
        "def get_semantic_similarity(text1, text2):\n",
        "    embedding1 = semantic_model.encode(text1, convert_to_tensor=True)\n",
        "    embedding2 = semantic_model.encode(text2, convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(embedding1, embedding2)\n",
        "    return similarity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R5OZpGgvIKKm"
      },
      "outputs": [],
      "source": [
        "def get_response_tf_idf(user_input):\n",
        "    text = user_input.lower()\n",
        "    text_vectorized = vector.transform([text])\n",
        "\n",
        "    similarity = cosine_similarity(text_vectorized, tfidf_matrix).flatten()\n",
        "\n",
        "    most_similar_index = similarity.argmax()\n",
        "\n",
        "    return df['response'].iloc[most_similar_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oCwNrAzAIMlM"
      },
      "outputs": [],
      "source": [
        "def get_response_transformer(user_input):\n",
        "    text = user_input.lower()\n",
        "    input_ids = my_tokenizer.encode(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = my_model.generate(input_ids, attention_mask=attention_mask, max_length=32, num_beams=5, no_repeat_ngram_size=2)\n",
        "        final_output = my_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        final_output = final_output.replace(text, '').strip()\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m84KaRkyIQmx"
      },
      "outputs": [],
      "source": [
        "# выбираем лучший респонс\n",
        "def get_better_response(user_input):\n",
        "    transformer_response = get_response_transformer(user_input)\n",
        "    tfidf_response = get_response_tf_idf(user_input)\n",
        "\n",
        "    semantic_similarity_transformer = get_semantic_similarity(user_input, transformer_response)\n",
        "    semantic_similarity_tfidf = get_semantic_similarity(user_input, tfidf_response)\n",
        "\n",
        "    if semantic_similarity_transformer > semantic_similarity_tfidf:\n",
        "        print('transformer: ', end='')\n",
        "        return transformer_response\n",
        "    else:\n",
        "        print('tf-idf: ', end='')\n",
        "        return tfidf_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3HaKOY3JR9S",
        "outputId": "b91b52d0-6e9b-4ba1-c7cf-3f27ca53b761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mChatBot: \u001b[0mTo end the dialogue, print \"bye\"\n",
            "\u001b[91mUser: \u001b[0mwhat are your hobbies?\n",
            "\u001b[92mChatBot: \u001b[0mtransformer: I like to play video games, read books and listen to classical music.\n",
            "\u001b[91mUser: \u001b[0mwhere do you work?\n",
            "\u001b[92mChatBot: \u001b[0mtransformer: I work in a restaurant.\n",
            "\u001b[91mUser: \u001b[0mhow can i cook a pizza?\n",
            "\u001b[92mChatBot: \u001b[0mtf-idf: step 1: preheat the oven to 375°f (190°c).\n",
            "step 2: spread a thin layer of tomato sauce on the pizza dough.\n",
            "step 3: sprinkle your favorite cheese on top of the sauce.\n",
            "step 4: add toppings of your choice—veggies, pepperoni, sausage, etc. \n",
            "step 5: place the pizza in the preheated oven.\n",
            "step 6: bake for 15-20 minutes or until the cheese is melted and the crust is golden brown. \n",
            "step 7: allow the pizza to cool slightly before serving. enjoy.\n",
            "\u001b[91mUser: \u001b[0mhow can i stay healthy in winter?\n",
            "\u001b[92mChatBot: \u001b[0mtf-idf: 1. make sure to dress warmly in layers when going out in cold weather.\n",
            "2. avoid going outdoors when the temperature drops significantly.\n",
            "3. stay hydrated and drink plenty of fluids to prevent dehydration.\n",
            "4. eat a balanced diet including lots of fresh fruits and vegetables to keep your immune system in check.\n",
            "5. get plenty of rest and sleep to help your body recover and stay healthy.\n",
            "6. cover your nose and mouth with a scarf or a face mask when going outside to prevent colds and flu.\n",
            "7. clean your hands frequently with soap and water or an alcohol-based sanitizer to keep germs at bay.\n",
            "8. avoid contact with people who are sick and practice social distancing.\n",
            "9. have a flu shot to reduce the risk of contracting the virus.\n",
            "10. avoid smoking and secondhand smoke to protect your respiratory system from cold-induced illnesses.\n",
            "\u001b[91mUser: \u001b[0mbye\n",
            "\u001b[92mChatBot: \u001b[0mGoodbye!\n"
          ]
        }
      ],
      "source": [
        "print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "print('To end the dialogue, print \"bye\"')\n",
        "while True:\n",
        "    user_input = input('\\033[91m'+'User: '+'\\033[0m')\n",
        "    if user_input.lower() == 'bye':\n",
        "        print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "        print('Goodbye!')\n",
        "        break\n",
        "    print('\\033[92m'+'ChatBot: '+'\\033[0m', end='')\n",
        "    print(get_better_response(user_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сначала выводит, каким методом был получен ответ, потом сам ответ."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
