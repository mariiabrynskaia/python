{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем книги\n",
    "# автор - Владислав Крапивин\n",
    "book1 = open('1981_crane_and_lightnings.txt').read() # Журавлёнок и молнии\n",
    "book2 = open('1992_bronze_boy.txt').read() # Бронзовый мальчик\n",
    "book3 = open('1996_grandson_and_his_brothers.txt').read() # Бабушкин внук и его братья\n",
    "book4 = open('2004_venus_across_the_sun.txt').read() # Прохождение Венеры по диску солнца\n",
    "book5 = open('2005_stomp_of_chess_horses.txt').read() # Топот шахматных лошадок\n",
    "book6 = open('2010_topol_kids.txt').read() # Тополята\n",
    "\n",
    "books = [book1, book2, book3, book4, book5, book6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # убираем стоп слова\n",
    "    words_filtered = []\n",
    "    tok = nltk.tokenize.WhitespaceTokenizer()\n",
    "    words = tok.tokenize(text)    \n",
    "    stop = stopwords.words('russian')\n",
    "    words_filtered = [word for word in words if word not in stop]\n",
    "    words_filtered = str(words_filtered)\n",
    "    # лемматизируем\n",
    "    doc = nlp(words_filtered)\n",
    "    words_lemma = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return words_lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cosine_similarity(books):\n",
    "    # предобработка\n",
    "    preprocessed_books = [preprocess(book) for book in books]\n",
    "    # конверт в стринг\n",
    "    preprocessed_books_to_str = [' '.join(book) for book in preprocessed_books]\n",
    "    # считаем cosine similarity\n",
    "    vectorizer = CountVectorizer()\n",
    "    book_vectors = vectorizer.fit_transform(preprocessed_books_to_str)\n",
    "    similarity_matrix = cosine_similarity(book_vectors)\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.4155801  0.5529125  0.41196701 0.37697352 0.44332618]\n",
      " [0.4155801  1.         0.55193657 0.39903809 0.37736098 0.45043214]\n",
      " [0.5529125  0.55193657 1.         0.53987934 0.50107014 0.5838519 ]\n",
      " [0.41196701 0.39903809 0.53987934 1.         0.37974367 0.43144149]\n",
      " [0.37697352 0.37736098 0.50107014 0.37974367 1.         0.44885354]\n",
      " [0.44332618 0.45043214 0.5838519  0.43144149 0.44885354 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cosine_result = count_cosine_similarity(books)\n",
    "print(cosine_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
